---
title: "Generalized_Function"
author: "Caelum Mroczek"
date: "2023-10-11"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE)

# Packages Vector
packages <- c("tidyverse", "sf", "raster", "terra", "ggplot2", "boot")

# Install packages not yet installed
installed_packages <- packages %in% rownames(installed.packages())
if (any(installed_packages == FALSE)) {
  install.packages(packages[!installed_packages])
}

# Packages loading
invisible(lapply(packages, library, character.only = TRUE))
```


## Loading Data
```{r}
#Dataset with stream reach code and lat/long for desired river
file_base <- "/Users/caelum/Library/Mobile Documents/com~apple~CloudDocs/NAU/Research/AZBFI_Manuscript/"

#Years to be included in period of record
year_list <- c(seq(from = 1991, to = 2020))

#Points that make up the river shape
River_Points <- read_csv(paste0(file_base, "SaltRiver/SaltRiver_points.csv"))
River_Points$ID <- 1:nrow(River_Points) #Add ID column to keep sites together

expanded_years <- expand.grid(Lat = unique(River_Points$Lat), Year = year_list) #add years to each site
River_Points <- merge(River_Points,expanded_years, by = "Lat", all.x = TRUE) 
River_Points <- River_Points[ order(River_Points$ID, River_Points$Year),]
River_Points <- River_Points[,c("ID","Year","Lat","Long")]

#Dataset of all predictors, keyed to HUC8 number
HUC_Predictors <- read_csv(paste0(file_base, "/VariableData/HUC_Variables/HUC_Dataset.csv"))

#Raster of HUC8 basin boundaries
HUC8_Basins <- rast(paste0(file_base, "/SaltRiver/HUC_Raster/HUC8_raster.tif")) #all of the various files for the raster need to be in the file
HUC8_Basins <- project(HUC8_Basins, "+proj=longlat") #set to correct projection

#DEM(30 meter) of state to pull elevation data 
DEM <- rast(paste0(file_base, "/BFI-Data/DEM_30M/AZ_DEM_30M.tif"))
DEM <- project(DEM, "+proj=longlat") #set to follow lat/long projection
```


# Use Lat/Long to assign HUC8 basin, site elevation, and associated HUC predcitors 
```{r}
#takes ~12 minutes to run with 161,000 rows of data
start.time <- Sys.time()
for (i in 1:nrow(River_Points)){
  p <- vect(River_Points[i,], geom=c("Long","Lat")) #define point geometry by lat/long
  huc <- extract(HUC8_Basins,p) #which HUC is the point within
  elev <- extract(DEM,p) #extract elevation of the point
  
  River_Points$HUC8[i] <- as.numeric(as.character(huc[,2]))
  River_Points$Elev_ft[i] <- (elev[,2])*3.281
}
end.time <- Sys.time()
time.taken <- round(end.time - start.time,2)
time.taken

```

# Use year and lat/long to assign historical temperature data
##### IN THE FUTURE I COULD CREATE A TABLE OF JUST HUC8 AND PRECIP/TEMP FOR EVERY YEAR IN RECORD #####
```{r}
#Extract Precipitation & Temperature Data
#took ~18 minutes to run 161,000 rows of data
start.time <- Sys.time()
for (i in 1:nrow(River_Points)){
  year <- River_Points$Year[i]
  #temp raster for the correct year
  whichRaster_T <- paste0(file_base,"BFI-Data/Temp_PRISM/OutputRasters_HUC/tmp",year,"_huc")
  thisRaster_T <- rast(whichRaster_T)
  #precip raster for the correct year
  whichRaster_P <- paste0(file_base,"BFI-Data/Precip_PRISM/OutputRasters_HUC/ppt",year,"_huc")
  thisRaster_P <- rast(whichRaster_P)
  #define the point 
  p <- vect(River_Points[i,], geom=c("Long","Lat"))
  #extract point data from correct rasters
  e_T <- extract(thisRaster_T,p)
  e_P <- extract(thisRaster_P,p)
  #assign values in dataframe
  River_Points$Temp_C[i] <- round(e_T[,2], 2)
  River_Points$Precip_mm[i] <- round(e_P[,2],2)
}
end.time <- Sys.time()
time.taken <- round(end.time - start.time,2)
time.taken
```

# Final dataset
```{r}
#assign HUC predictors to each site according to HUC location
RiverPoints_AllData <- merge(River_Points, HUC_Predictors, by = "HUC8", all.x = TRUE)
RiverPoints_AllData <- RiverPoints_AllData[,-c(9)]
RiverPoints_AllData <- RiverPoints_AllData[,c(2,1,3:52)]
```

#Run ML Model to fill in year data that is missing
```{r}
xgb_model <- readRDS("/Users/caelum/Documents/GitHub/BFI_Research/XGB_Training/10FoldCV_HUC_XGBModel.rda")

#Hard coded the path for now
predicting_HUC <- read_csv(file = "/Users/caelum/Documents/GitHub/BFI_Research/Base-Flow-Spatial/Data/predicting_HUC.csv")

RiverPoints_AllData <- read_csv(file = "/Users/caelum/Documents/GitHub/BFI_Research/Base-Flow-Spatial/Data/RiverPoints_ALL.csv")

#######################

RiverPoints_ALL <- read_csv("~/Documents/GitHub/BFI_Research/Base-Flow-Spatial/Data/RiverPoints_ALL.csv")
RiverPoints_ALL <-  subset(RiverPoints_ALL, select = -c(WATER_PERCENT, KEY))
RiverPoints_ALL <- RiverPoints_ALL[,c(2:4,1,5:50)]

#need to do inverse log of the values since the model outputs logged BFI
RiverPoints_ALL$predictedBFI <- inv.logit(predict(object = HUC_model,
                     newdata = as.matrix(RiverPoints_ALL)))


mean_predictedBFI <- RiverPoints_ALL %>%
  group_by(LAT) %>%
  filter(!is.na(predictedBFI)) %>%  # Remove NA values in predictedBFI
  summarise(mean_predictedBFI = mean(predictedBFI, na.rm = TRUE))

write_csv(mean_predictedBFI, file = "/Volumes/Mroczek,Caelum/mean_predictedBFI.csv")
```

